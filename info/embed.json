{"short":"<p>Image embeddings are a way to find similarities between two pairs of\nimages (they also have other applications, as described in the ‘Learn\nMore’ link above). Here, we will run an embedding over a set of images.\nThen, the visualization on the right will allow you to click on an image\nand sort the remainder of the collection based on similarity to the\nselected image. Scores at the bottom range from 0 (no similarity) to 100\n(identical). Try any of the large example datasets; they have\npre-computed embedings making them fast and easy to experiment with.<\/p>","long":"<p>Image embeddings are a way to find similarities between pairs of\nimages (they also have other applications, as described in the ‘Learn\nMore’ link above). Here, we will run an embedding over a set of images.\nThen, the visualization on the right will allow you to click on an image\nand sort the remainder of the collection based on similarity to the\nselected image. Scores at the bottom range from 0 (no similarity) to 100\n(identical). Try any of the large example datasets; they have\npre-computed embedings making them fast and easy to experiment with.<\/p>\n<h3 id=\"references-4\">References<\/h3>\n<pre><code>@misc{wu2020visual,\n      title={Visual Transformers: Token-based Image Representation and Processing for Computer Vision}, \n      author={Bichen Wu and Chenfeng Xu and Xiaoliang Dai and Alvin Wan and Peizhao Zhang and Zhicheng Yan and Masayoshi Tomizuka and Joseph Gonzalez and Kurt Keutzer and Peter Vajda},\n      year={2020},\n      eprint={2006.03677},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV}\n}<\/code><\/pre>"}
