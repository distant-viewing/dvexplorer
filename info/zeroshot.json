{"short":"<p>Multimodal zero-shot learning extends and combines the ideas behind\nobject detection and image embedding. The goal is to identify a\nsimilarity score between a textual description and an image such that\nthe score is large when the description serves as a good caption for the\nimage. Captions allow us to search for any categories (however complex)\nwithout creating a specialized model. Here, we first run an embedding\nover the entire collection and then, on the right, allow for inputting a\nsearch string. We suggest starting with the large example datasets as\nthey have pre-computed embeddings and quickly show the powerful\npossibilities of this approach.<\/p>","long":"<p>Multimodal zero-shot learning extends and combines the ideas behind\nobject detection and image embedding. The goal is to identify a\nsimilarity score between a textual description and an image such that\nthe score is large when the description serves as a good caption for the\nimage. Captions allow us to search for any categories (however complex)\nwithout having to create a specialized model for them. Here, we first\nrun an embedding over the entire collection and then, on the right,\nallow for inputting a search string. We suggest starting with the large\nexample datasets as they have pre-computed embeddings and quickly show\nthe powerful possibilities of this approach.<\/p>\n<h3 id=\"references-11\">References<\/h3>\n<pre><code>@misc{zhai2023sigmoid,\n      title={Sigmoid Loss for Language Image Pre-Training}, \n      author={Xiaohua Zhai and Basil Mustafa and Alexander Kolesnikov and Lucas Beyer},\n      year={2023},\n      eprint={2303.15343},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV}\n}<\/code><\/pre>"}
