{"short":"<p>Transcription, also known as speech-to-text, is the process of taking\nan audio file and converting it into a machine-readable text of the\nwords being spoken. Most models, as is the one here, are\nlanguage-dependant. You will need to select your desired language from\nthe menu below before getting started. The output of the model provides\na exact timestamp for where a word is spoken. Clicking on a word in the\ntranscript will jump the video to the time stamp of when it predicts\nthat word is being spoken.<\/p>","long":"<p>Transcription, also known as speech-to-text, is the process of taking\nan audio file and converting it into a machine-readable text of the\nwords being spoken. Most models, as is the one here, are\nlanguage-dependant. You will need to select your desired language from\nthe menu below before getting started. The output of the model provides\na exact timestamp for where a word is spoken. Clicking on a word in the\ntranscript will jump the video to the time stamp of when it predicts\nthat word is being spoken.<\/p>\n<h3 id=\"references-6\">References<\/h3>\n<pre><code>@misc{radford2022whisper,\n  doi = {10.48550/ARXIV.2212.04356},\n  url = {https://arxiv.org/abs/2212.04356},\n  author = {Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},\n  title = {Robust Speech Recognition via Large-Scale Weak Supervision},\n  publisher = {arXiv},\n  year = {2022},\n  copyright = {arXiv.org perpetual, non-exclusive license}\n}<\/code><\/pre>"}
