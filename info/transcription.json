{"short":"<p>Transcription, also known as speech-to-text, takes an audio file and\nconverts it into a machine-readable text of the words being spoken. Most\nmodels, as is the one here, are language-dependent. You must select your\ndesired language from the menu below before getting started. The model\noutput provides a timestamp for where a word is spoken. Clicking on a\nword in the transcript will jump the video to the time stamp when it\npredicts the word being spoken.<\/p>","long":"<p>Transcription, also known as speech-to-text, takes an audio file and\nconverts it into a machine-readable text of the words being spoken. Most\nmodels, as is the one here, are language-dependent. You must select your\ndesired language from the menu below before getting started. The model\noutput provides a timestamp for where a word is spoken. Clicking on a\nword in the transcript will jump the video to the time stamp when it\npredicts the word being spoken.<\/p>\n<h3 id=\"references-6\">References<\/h3>\n<pre><code>@misc{radford2022whisper,\n  doi = {10.48550/ARXIV.2212.04356},\n  url = {https://arxiv.org/abs/2212.04356},\n  author = {Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},\n  title = {Robust Speech Recognition via Large-Scale Weak Supervision},\n  publisher = {arXiv},\n  year = {2022},\n  copyright = {arXiv.org perpetual, non-exclusive license}\n}<\/code><\/pre>"}
