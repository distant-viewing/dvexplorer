{"short":"<p>Diarization is another audio-based annotation. It attempts to\nidentify when different speakers are speaking in an audio recording. It\nis very useful for studying film and television data, often being paired\nwith the transcription task. Note that the model used here begins to\nhave trouble when the number of speakers is large. The Python code\nprovides some ways of addressing this issue with larger datasets.<\/p>","long":"<p>Diarization is another audio-based annotation. It attempts to\nidentify when different speakers are speaking in an audio recording. It\nis very useful for studying film and television data, often being paired\nwith the transcription task. Note that the model used here begins to\nhave trouble when the number of speakers is large. The Python code\nprovides some ways of addressing this issue with larger datasets.<\/p>\n<h3 id=\"references-7\">References<\/h3>\n<pre><code>@inproceedings{Plaquet23,\n  author={Alexis Plaquet and Hervé Bredin},\n  title={{Powerset multi-class cross entropy loss for neural speaker diarization}},\n  year=2023,\n  booktitle={Proc. INTERSPEECH 2023},\n}\n@inproceedings{Bredin23,\n  author={Hervé Bredin},\n  title={{pyannote.audio 2.1 speaker diarization pipeline: principle, benchmark, and recipe}},\n  year=2023,\n  booktitle={Proc. INTERSPEECH 2023},\n}<\/code><\/pre>"}
